{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.2     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.0.4     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.2\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.1.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.4.0     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[39m\n",
      "cols(\n",
      "  model = \u001b[31mcol_character()\u001b[39m,\n",
      "  preprocessing = \u001b[31mcol_character()\u001b[39m,\n",
      "  accuracy = \u001b[32mcol_double()\u001b[39m,\n",
      "  precision = \u001b[32mcol_double()\u001b[39m,\n",
      "  sensitivity = \u001b[32mcol_double()\u001b[39m,\n",
      "  specificity = \u001b[32mcol_double()\u001b[39m,\n",
      "  informedness = \u001b[32mcol_double()\u001b[39m,\n",
      "  dor = \u001b[32mcol_double()\u001b[39m,\n",
      "  ami = \u001b[32mcol_double()\u001b[39m,\n",
      "  `outlier informedness` = \u001b[32mcol_double()\u001b[39m,\n",
      "  `cv informedness` = \u001b[32mcol_double()\u001b[39m,\n",
      "  `mad informedness` = \u001b[32mcol_double()\u001b[39m,\n",
      "  `commit hash` = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A spec_tbl_df: 38 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>qda</td><td>robust scaling       </td><td>0.8140</td><td>0.8095</td><td>0.8763</td><td>0.7333</td><td>0.6096</td><td>19.480</td><td>0.2993</td><td>0.4833</td><td>0.6036</td><td>0.08135</td><td>5236d5b</td></tr>\n",
       "\t<tr><td>lda</td><td>robust scaling       </td><td>0.8140</td><td>0.8155</td><td>0.8660</td><td>0.7467</td><td>0.6126</td><td>19.040</td><td>0.2981</td><td>0.5500</td><td>0.5782</td><td>0.07821</td><td>9b44485</td></tr>\n",
       "\t<tr><td>dtc</td><td>robust scaling       </td><td>0.7791</td><td>0.7565</td><td>0.8969</td><td>0.6267</td><td>0.5236</td><td>14.600</td><td>0.2389</td><td>0.6500</td><td>0.5143</td><td>0.07692</td><td>ad170e6</td></tr>\n",
       "\t<tr><td>sgb</td><td>robust scaling       </td><td>0.8081</td><td>0.7963</td><td>0.8866</td><td>0.7067</td><td>0.5933</td><td>18.830</td><td>0.2895</td><td>0.5667</td><td>0.5879</td><td>0.07756</td><td>87c9f52</td></tr>\n",
       "\t<tr><td>rfc</td><td>robust scaling       </td><td>0.8314</td><td>0.8269</td><td>0.8866</td><td>0.7600</td><td>0.6466</td><td>24.760</td><td>0.3384</td><td>0.5500</td><td>0.5627</td><td>0.08640</td><td>604f618</td></tr>\n",
       "\t<tr><td>rfc</td><td>isomap               </td><td>0.8081</td><td>0.8200</td><td>0.8454</td><td>0.7600</td><td>0.6054</td><td>17.310</td><td>0.2851</td><td>0.4667</td><td>0.6357</td><td>0.11830</td><td>614ff30</td></tr>\n",
       "\t<tr><td>rfc</td><td>pca                  </td><td>0.8430</td><td>0.8365</td><td>0.8969</td><td>0.7733</td><td>0.6702</td><td>29.680</td><td>0.3668</td><td>0.6500</td><td>0.5782</td><td>0.09998</td><td>e16ba46</td></tr>\n",
       "\t<tr><td>rfc</td><td>lle                  </td><td>0.7965</td><td>0.8444</td><td>0.7835</td><td>0.8133</td><td>0.5968</td><td>15.770</td><td>0.2693</td><td>0.4667</td><td>0.5334</td><td>0.14640</td><td>4bdf43f</td></tr>\n",
       "\t<tr><td>rfc</td><td>lle hessian          </td><td>0.8198</td><td>0.8235</td><td>0.8660</td><td>0.7600</td><td>0.6260</td><td>20.460</td><td>0.3105</td><td>0.4833</td><td>0.5205</td><td>0.09570</td><td>3be6109</td></tr>\n",
       "\t<tr><td>rfc</td><td>lle modified         </td><td>0.7849</td><td>0.8061</td><td>0.8144</td><td>0.7467</td><td>0.5611</td><td>12.940</td><td>0.2394</td><td>0.4667</td><td>0.5314</td><td>0.10560</td><td>72f0897</td></tr>\n",
       "\t<tr><td>rfc</td><td>factor analysis      </td><td>0.8023</td><td>0.8387</td><td>0.8041</td><td>0.8000</td><td>0.6041</td><td>16.420</td><td>0.2772</td><td>0.4500</td><td>0.5743</td><td>0.10300</td><td>08a08cd</td></tr>\n",
       "\t<tr><td>rfc</td><td>feature agglomeration</td><td>0.8081</td><td>0.8200</td><td>0.8454</td><td>0.7600</td><td>0.6054</td><td>17.310</td><td>0.2851</td><td>0.6500</td><td>0.5835</td><td>0.10070</td><td>0be2375</td></tr>\n",
       "\t<tr><td>rfc</td><td>nca                  </td><td>0.8081</td><td>0.8404</td><td>0.8144</td><td>0.8000</td><td>0.6144</td><td>17.560</td><td>0.2882</td><td>0.4500</td><td>0.5196</td><td>0.11650</td><td>59c3c02</td></tr>\n",
       "\t<tr><td>rfc</td><td>standard scaling     </td><td>0.8023</td><td>0.8119</td><td>0.8454</td><td>0.7467</td><td>0.5920</td><td>16.110</td><td>0.2731</td><td>0.6500</td><td>0.5421</td><td>0.09368</td><td>16e71aa</td></tr>\n",
       "\t<tr><td>rfc</td><td>none                 </td><td>0.8023</td><td>0.8119</td><td>0.8454</td><td>0.7467</td><td>0.5920</td><td>16.110</td><td>0.2731</td><td>0.6500</td><td>0.5421</td><td>0.09368</td><td>cde032e</td></tr>\n",
       "\t<tr><td>rnc</td><td>robust scaling       </td><td>0.8198</td><td>0.8438</td><td>0.8351</td><td>0.8000</td><td>0.6351</td><td>20.250</td><td>0.3116</td><td>0.4500</td><td>0.6162</td><td>0.08429</td><td>c47f862</td></tr>\n",
       "\t<tr><td>knn</td><td>robust scaling       </td><td>0.8372</td><td>0.8791</td><td>0.8247</td><td>0.8533</td><td>0.6781</td><td>27.380</td><td>0.3575</td><td>0.5500</td><td>0.6219</td><td>0.10520</td><td>3ee0a51</td></tr>\n",
       "\t<tr><td>knn</td><td>standard scaling     </td><td>0.8198</td><td>0.8367</td><td>0.8454</td><td>0.7867</td><td>0.6320</td><td>20.160</td><td>0.3105</td><td>0.6643</td><td>0.1176</td><td>0.46670</td><td>2544121</td></tr>\n",
       "\t<tr><td>knn</td><td>none                 </td><td>0.7384</td><td>0.7321</td><td>0.8454</td><td>0.6000</td><td>0.4454</td><td> 8.200</td><td>0.1621</td><td>0.3167</td><td>0.4592</td><td>0.07587</td><td>26c115c</td></tr>\n",
       "\t<tr><td>knn</td><td>pca                  </td><td>0.8372</td><td>0.8286</td><td>0.8969</td><td>0.7600</td><td>0.6569</td><td>27.550</td><td>0.3535</td><td>0.7500</td><td>0.5506</td><td>0.12090</td><td>7ace118</td></tr>\n",
       "\t<tr><td>knn</td><td>isomap               </td><td>0.8140</td><td>0.8155</td><td>0.8660</td><td>0.7467</td><td>0.6126</td><td>19.040</td><td>0.2981</td><td>0.5500</td><td>0.6076</td><td>0.08374</td><td>38c3c33</td></tr>\n",
       "\t<tr><td>knn</td><td>lle hessian          </td><td>0.8023</td><td>0.8387</td><td>0.8041</td><td>0.8000</td><td>0.6041</td><td>16.420</td><td>0.2772</td><td>0.2667</td><td>0.5712</td><td>0.13890</td><td>b85af4b</td></tr>\n",
       "\t<tr><td>knn</td><td>lle                  </td><td>0.8198</td><td>0.8235</td><td>0.8660</td><td>0.7600</td><td>0.6260</td><td>20.460</td><td>0.3105</td><td>0.5667</td><td>0.5869</td><td>0.10690</td><td>0191ede</td></tr>\n",
       "\t<tr><td>knn</td><td>lle modified         </td><td>0.8081</td><td>0.8077</td><td>0.8660</td><td>0.7333</td><td>0.5993</td><td>17.770</td><td>0.2860</td><td>0.4667</td><td>0.5676</td><td>0.12940</td><td>5af463b</td></tr>\n",
       "\t<tr><td>knn</td><td>factor analysis      </td><td>0.8721</td><td>0.8788</td><td>0.8969</td><td>0.8400</td><td>0.7369</td><td>45.670</td><td>0.4408</td><td>0.6333</td><td>0.6164</td><td>0.10710</td><td>05e50d5</td></tr>\n",
       "\t<tr><td>knn</td><td>feature agglomeration</td><td>0.8372</td><td>0.8791</td><td>0.8247</td><td>0.8533</td><td>0.6781</td><td>27.380</td><td>0.3575</td><td>0.5500</td><td>0.6219</td><td>0.10520</td><td>10fa6ee</td></tr>\n",
       "\t<tr><td>knn</td><td>nca                  </td><td>0.8256</td><td>0.8252</td><td>0.8763</td><td>0.7600</td><td>0.6363</td><td>22.430</td><td>0.3241</td><td>0.4667</td><td>0.5450</td><td>0.09647</td><td>cfdc2d4</td></tr>\n",
       "\t<tr><td>lrc</td><td>robust scaling       </td><td>0.8256</td><td>0.8526</td><td>0.8351</td><td>0.8133</td><td>0.6484</td><td>22.060</td><td>0.3253</td><td>0.5500</td><td>0.6040</td><td>0.06880</td><td>3ed1fbc</td></tr>\n",
       "\t<tr><td>lrc</td><td>isomap               </td><td>0.7442</td><td>0.7849</td><td>0.7526</td><td>0.7333</td><td>0.4859</td><td> 8.365</td><td>0.1731</td><td>0.3667</td><td>0.5397</td><td>0.07043</td><td>09c73d2</td></tr>\n",
       "\t<tr><td>lrc</td><td>feature agglomeration</td><td>0.8256</td><td>0.8526</td><td>0.8351</td><td>0.8133</td><td>0.6484</td><td>22.060</td><td>0.3253</td><td>0.5500</td><td>0.6040</td><td>0.06880</td><td>f6ca049</td></tr>\n",
       "\t<tr><td>lrc</td><td>factor analysis      </td><td>0.8256</td><td>0.8602</td><td>0.8247</td><td>0.8267</td><td>0.6514</td><td>22.440</td><td>0.3274</td><td>0.4667</td><td>0.6050</td><td>0.10020</td><td>20a1399</td></tr>\n",
       "\t<tr><td>lrc</td><td>standard scaling     </td><td>0.8140</td><td>0.8495</td><td>0.8144</td><td>0.8133</td><td>0.6278</td><td>19.120</td><td>0.3016</td><td>0.5500</td><td>0.6040</td><td>0.06929</td><td>f3b8dbb</td></tr>\n",
       "\t<tr><td>lrc</td><td>pca                  </td><td>0.8314</td><td>0.8469</td><td>0.8557</td><td>0.8000</td><td>0.6557</td><td>23.710</td><td>0.3369</td><td>0.4500</td><td>0.5569</td><td>0.05593</td><td>a9faa26</td></tr>\n",
       "\t<tr><td>lrc</td><td>lle                  </td><td>0.8547</td><td>0.8750</td><td>0.8660</td><td>0.8400</td><td>0.7060</td><td>33.920</td><td>0.3948</td><td>0.7333</td><td>0.5410</td><td>0.15540</td><td>0330f84</td></tr>\n",
       "\t<tr><td>lrc</td><td>lle hessian          </td><td>0.8256</td><td>0.8602</td><td>0.8247</td><td>0.8267</td><td>0.6514</td><td>22.440</td><td>0.3274</td><td>0.5500</td><td>0.5934</td><td>0.09136</td><td>f89dea8</td></tr>\n",
       "\t<tr><td>lrc</td><td>lle modified         </td><td>0.8140</td><td>0.8495</td><td>0.8144</td><td>0.8133</td><td>0.6278</td><td>19.120</td><td>0.3016</td><td>0.5500</td><td>0.6168</td><td>0.07125</td><td>9a8b7e3</td></tr>\n",
       "\t<tr><td>lrc</td><td>nca                  </td><td>0.8314</td><td>0.8617</td><td>0.8351</td><td>0.8267</td><td>0.6617</td><td>24.140</td><td>0.3396</td><td>0.5500</td><td>0.5639</td><td>0.08217</td><td>a9e7758</td></tr>\n",
       "\t<tr><td>lrc</td><td>none                 </td><td>0.8140</td><td>0.8495</td><td>0.8144</td><td>0.8133</td><td>0.6278</td><td>19.120</td><td>0.3016</td><td>0.5500</td><td>0.6040</td><td>0.06929</td><td>eebed59</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A spec\\_tbl\\_df: 38 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t qda & robust scaling        & 0.8140 & 0.8095 & 0.8763 & 0.7333 & 0.6096 & 19.480 & 0.2993 & 0.4833 & 0.6036 & 0.08135 & 5236d5b\\\\\n",
       "\t lda & robust scaling        & 0.8140 & 0.8155 & 0.8660 & 0.7467 & 0.6126 & 19.040 & 0.2981 & 0.5500 & 0.5782 & 0.07821 & 9b44485\\\\\n",
       "\t dtc & robust scaling        & 0.7791 & 0.7565 & 0.8969 & 0.6267 & 0.5236 & 14.600 & 0.2389 & 0.6500 & 0.5143 & 0.07692 & ad170e6\\\\\n",
       "\t sgb & robust scaling        & 0.8081 & 0.7963 & 0.8866 & 0.7067 & 0.5933 & 18.830 & 0.2895 & 0.5667 & 0.5879 & 0.07756 & 87c9f52\\\\\n",
       "\t rfc & robust scaling        & 0.8314 & 0.8269 & 0.8866 & 0.7600 & 0.6466 & 24.760 & 0.3384 & 0.5500 & 0.5627 & 0.08640 & 604f618\\\\\n",
       "\t rfc & isomap                & 0.8081 & 0.8200 & 0.8454 & 0.7600 & 0.6054 & 17.310 & 0.2851 & 0.4667 & 0.6357 & 0.11830 & 614ff30\\\\\n",
       "\t rfc & pca                   & 0.8430 & 0.8365 & 0.8969 & 0.7733 & 0.6702 & 29.680 & 0.3668 & 0.6500 & 0.5782 & 0.09998 & e16ba46\\\\\n",
       "\t rfc & lle                   & 0.7965 & 0.8444 & 0.7835 & 0.8133 & 0.5968 & 15.770 & 0.2693 & 0.4667 & 0.5334 & 0.14640 & 4bdf43f\\\\\n",
       "\t rfc & lle hessian           & 0.8198 & 0.8235 & 0.8660 & 0.7600 & 0.6260 & 20.460 & 0.3105 & 0.4833 & 0.5205 & 0.09570 & 3be6109\\\\\n",
       "\t rfc & lle modified          & 0.7849 & 0.8061 & 0.8144 & 0.7467 & 0.5611 & 12.940 & 0.2394 & 0.4667 & 0.5314 & 0.10560 & 72f0897\\\\\n",
       "\t rfc & factor analysis       & 0.8023 & 0.8387 & 0.8041 & 0.8000 & 0.6041 & 16.420 & 0.2772 & 0.4500 & 0.5743 & 0.10300 & 08a08cd\\\\\n",
       "\t rfc & feature agglomeration & 0.8081 & 0.8200 & 0.8454 & 0.7600 & 0.6054 & 17.310 & 0.2851 & 0.6500 & 0.5835 & 0.10070 & 0be2375\\\\\n",
       "\t rfc & nca                   & 0.8081 & 0.8404 & 0.8144 & 0.8000 & 0.6144 & 17.560 & 0.2882 & 0.4500 & 0.5196 & 0.11650 & 59c3c02\\\\\n",
       "\t rfc & standard scaling      & 0.8023 & 0.8119 & 0.8454 & 0.7467 & 0.5920 & 16.110 & 0.2731 & 0.6500 & 0.5421 & 0.09368 & 16e71aa\\\\\n",
       "\t rfc & none                  & 0.8023 & 0.8119 & 0.8454 & 0.7467 & 0.5920 & 16.110 & 0.2731 & 0.6500 & 0.5421 & 0.09368 & cde032e\\\\\n",
       "\t rnc & robust scaling        & 0.8198 & 0.8438 & 0.8351 & 0.8000 & 0.6351 & 20.250 & 0.3116 & 0.4500 & 0.6162 & 0.08429 & c47f862\\\\\n",
       "\t knn & robust scaling        & 0.8372 & 0.8791 & 0.8247 & 0.8533 & 0.6781 & 27.380 & 0.3575 & 0.5500 & 0.6219 & 0.10520 & 3ee0a51\\\\\n",
       "\t knn & standard scaling      & 0.8198 & 0.8367 & 0.8454 & 0.7867 & 0.6320 & 20.160 & 0.3105 & 0.6643 & 0.1176 & 0.46670 & 2544121\\\\\n",
       "\t knn & none                  & 0.7384 & 0.7321 & 0.8454 & 0.6000 & 0.4454 &  8.200 & 0.1621 & 0.3167 & 0.4592 & 0.07587 & 26c115c\\\\\n",
       "\t knn & pca                   & 0.8372 & 0.8286 & 0.8969 & 0.7600 & 0.6569 & 27.550 & 0.3535 & 0.7500 & 0.5506 & 0.12090 & 7ace118\\\\\n",
       "\t knn & isomap                & 0.8140 & 0.8155 & 0.8660 & 0.7467 & 0.6126 & 19.040 & 0.2981 & 0.5500 & 0.6076 & 0.08374 & 38c3c33\\\\\n",
       "\t knn & lle hessian           & 0.8023 & 0.8387 & 0.8041 & 0.8000 & 0.6041 & 16.420 & 0.2772 & 0.2667 & 0.5712 & 0.13890 & b85af4b\\\\\n",
       "\t knn & lle                   & 0.8198 & 0.8235 & 0.8660 & 0.7600 & 0.6260 & 20.460 & 0.3105 & 0.5667 & 0.5869 & 0.10690 & 0191ede\\\\\n",
       "\t knn & lle modified          & 0.8081 & 0.8077 & 0.8660 & 0.7333 & 0.5993 & 17.770 & 0.2860 & 0.4667 & 0.5676 & 0.12940 & 5af463b\\\\\n",
       "\t knn & factor analysis       & 0.8721 & 0.8788 & 0.8969 & 0.8400 & 0.7369 & 45.670 & 0.4408 & 0.6333 & 0.6164 & 0.10710 & 05e50d5\\\\\n",
       "\t knn & feature agglomeration & 0.8372 & 0.8791 & 0.8247 & 0.8533 & 0.6781 & 27.380 & 0.3575 & 0.5500 & 0.6219 & 0.10520 & 10fa6ee\\\\\n",
       "\t knn & nca                   & 0.8256 & 0.8252 & 0.8763 & 0.7600 & 0.6363 & 22.430 & 0.3241 & 0.4667 & 0.5450 & 0.09647 & cfdc2d4\\\\\n",
       "\t lrc & robust scaling        & 0.8256 & 0.8526 & 0.8351 & 0.8133 & 0.6484 & 22.060 & 0.3253 & 0.5500 & 0.6040 & 0.06880 & 3ed1fbc\\\\\n",
       "\t lrc & isomap                & 0.7442 & 0.7849 & 0.7526 & 0.7333 & 0.4859 &  8.365 & 0.1731 & 0.3667 & 0.5397 & 0.07043 & 09c73d2\\\\\n",
       "\t lrc & feature agglomeration & 0.8256 & 0.8526 & 0.8351 & 0.8133 & 0.6484 & 22.060 & 0.3253 & 0.5500 & 0.6040 & 0.06880 & f6ca049\\\\\n",
       "\t lrc & factor analysis       & 0.8256 & 0.8602 & 0.8247 & 0.8267 & 0.6514 & 22.440 & 0.3274 & 0.4667 & 0.6050 & 0.10020 & 20a1399\\\\\n",
       "\t lrc & standard scaling      & 0.8140 & 0.8495 & 0.8144 & 0.8133 & 0.6278 & 19.120 & 0.3016 & 0.5500 & 0.6040 & 0.06929 & f3b8dbb\\\\\n",
       "\t lrc & pca                   & 0.8314 & 0.8469 & 0.8557 & 0.8000 & 0.6557 & 23.710 & 0.3369 & 0.4500 & 0.5569 & 0.05593 & a9faa26\\\\\n",
       "\t lrc & lle                   & 0.8547 & 0.8750 & 0.8660 & 0.8400 & 0.7060 & 33.920 & 0.3948 & 0.7333 & 0.5410 & 0.15540 & 0330f84\\\\\n",
       "\t lrc & lle hessian           & 0.8256 & 0.8602 & 0.8247 & 0.8267 & 0.6514 & 22.440 & 0.3274 & 0.5500 & 0.5934 & 0.09136 & f89dea8\\\\\n",
       "\t lrc & lle modified          & 0.8140 & 0.8495 & 0.8144 & 0.8133 & 0.6278 & 19.120 & 0.3016 & 0.5500 & 0.6168 & 0.07125 & 9a8b7e3\\\\\n",
       "\t lrc & nca                   & 0.8314 & 0.8617 & 0.8351 & 0.8267 & 0.6617 & 24.140 & 0.3396 & 0.5500 & 0.5639 & 0.08217 & a9e7758\\\\\n",
       "\t lrc & none                  & 0.8140 & 0.8495 & 0.8144 & 0.8133 & 0.6278 & 19.120 & 0.3016 & 0.5500 & 0.6040 & 0.06929 & eebed59\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A spec_tbl_df: 38 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| qda | robust scaling        | 0.8140 | 0.8095 | 0.8763 | 0.7333 | 0.6096 | 19.480 | 0.2993 | 0.4833 | 0.6036 | 0.08135 | 5236d5b |\n",
       "| lda | robust scaling        | 0.8140 | 0.8155 | 0.8660 | 0.7467 | 0.6126 | 19.040 | 0.2981 | 0.5500 | 0.5782 | 0.07821 | 9b44485 |\n",
       "| dtc | robust scaling        | 0.7791 | 0.7565 | 0.8969 | 0.6267 | 0.5236 | 14.600 | 0.2389 | 0.6500 | 0.5143 | 0.07692 | ad170e6 |\n",
       "| sgb | robust scaling        | 0.8081 | 0.7963 | 0.8866 | 0.7067 | 0.5933 | 18.830 | 0.2895 | 0.5667 | 0.5879 | 0.07756 | 87c9f52 |\n",
       "| rfc | robust scaling        | 0.8314 | 0.8269 | 0.8866 | 0.7600 | 0.6466 | 24.760 | 0.3384 | 0.5500 | 0.5627 | 0.08640 | 604f618 |\n",
       "| rfc | isomap                | 0.8081 | 0.8200 | 0.8454 | 0.7600 | 0.6054 | 17.310 | 0.2851 | 0.4667 | 0.6357 | 0.11830 | 614ff30 |\n",
       "| rfc | pca                   | 0.8430 | 0.8365 | 0.8969 | 0.7733 | 0.6702 | 29.680 | 0.3668 | 0.6500 | 0.5782 | 0.09998 | e16ba46 |\n",
       "| rfc | lle                   | 0.7965 | 0.8444 | 0.7835 | 0.8133 | 0.5968 | 15.770 | 0.2693 | 0.4667 | 0.5334 | 0.14640 | 4bdf43f |\n",
       "| rfc | lle hessian           | 0.8198 | 0.8235 | 0.8660 | 0.7600 | 0.6260 | 20.460 | 0.3105 | 0.4833 | 0.5205 | 0.09570 | 3be6109 |\n",
       "| rfc | lle modified          | 0.7849 | 0.8061 | 0.8144 | 0.7467 | 0.5611 | 12.940 | 0.2394 | 0.4667 | 0.5314 | 0.10560 | 72f0897 |\n",
       "| rfc | factor analysis       | 0.8023 | 0.8387 | 0.8041 | 0.8000 | 0.6041 | 16.420 | 0.2772 | 0.4500 | 0.5743 | 0.10300 | 08a08cd |\n",
       "| rfc | feature agglomeration | 0.8081 | 0.8200 | 0.8454 | 0.7600 | 0.6054 | 17.310 | 0.2851 | 0.6500 | 0.5835 | 0.10070 | 0be2375 |\n",
       "| rfc | nca                   | 0.8081 | 0.8404 | 0.8144 | 0.8000 | 0.6144 | 17.560 | 0.2882 | 0.4500 | 0.5196 | 0.11650 | 59c3c02 |\n",
       "| rfc | standard scaling      | 0.8023 | 0.8119 | 0.8454 | 0.7467 | 0.5920 | 16.110 | 0.2731 | 0.6500 | 0.5421 | 0.09368 | 16e71aa |\n",
       "| rfc | none                  | 0.8023 | 0.8119 | 0.8454 | 0.7467 | 0.5920 | 16.110 | 0.2731 | 0.6500 | 0.5421 | 0.09368 | cde032e |\n",
       "| rnc | robust scaling        | 0.8198 | 0.8438 | 0.8351 | 0.8000 | 0.6351 | 20.250 | 0.3116 | 0.4500 | 0.6162 | 0.08429 | c47f862 |\n",
       "| knn | robust scaling        | 0.8372 | 0.8791 | 0.8247 | 0.8533 | 0.6781 | 27.380 | 0.3575 | 0.5500 | 0.6219 | 0.10520 | 3ee0a51 |\n",
       "| knn | standard scaling      | 0.8198 | 0.8367 | 0.8454 | 0.7867 | 0.6320 | 20.160 | 0.3105 | 0.6643 | 0.1176 | 0.46670 | 2544121 |\n",
       "| knn | none                  | 0.7384 | 0.7321 | 0.8454 | 0.6000 | 0.4454 |  8.200 | 0.1621 | 0.3167 | 0.4592 | 0.07587 | 26c115c |\n",
       "| knn | pca                   | 0.8372 | 0.8286 | 0.8969 | 0.7600 | 0.6569 | 27.550 | 0.3535 | 0.7500 | 0.5506 | 0.12090 | 7ace118 |\n",
       "| knn | isomap                | 0.8140 | 0.8155 | 0.8660 | 0.7467 | 0.6126 | 19.040 | 0.2981 | 0.5500 | 0.6076 | 0.08374 | 38c3c33 |\n",
       "| knn | lle hessian           | 0.8023 | 0.8387 | 0.8041 | 0.8000 | 0.6041 | 16.420 | 0.2772 | 0.2667 | 0.5712 | 0.13890 | b85af4b |\n",
       "| knn | lle                   | 0.8198 | 0.8235 | 0.8660 | 0.7600 | 0.6260 | 20.460 | 0.3105 | 0.5667 | 0.5869 | 0.10690 | 0191ede |\n",
       "| knn | lle modified          | 0.8081 | 0.8077 | 0.8660 | 0.7333 | 0.5993 | 17.770 | 0.2860 | 0.4667 | 0.5676 | 0.12940 | 5af463b |\n",
       "| knn | factor analysis       | 0.8721 | 0.8788 | 0.8969 | 0.8400 | 0.7369 | 45.670 | 0.4408 | 0.6333 | 0.6164 | 0.10710 | 05e50d5 |\n",
       "| knn | feature agglomeration | 0.8372 | 0.8791 | 0.8247 | 0.8533 | 0.6781 | 27.380 | 0.3575 | 0.5500 | 0.6219 | 0.10520 | 10fa6ee |\n",
       "| knn | nca                   | 0.8256 | 0.8252 | 0.8763 | 0.7600 | 0.6363 | 22.430 | 0.3241 | 0.4667 | 0.5450 | 0.09647 | cfdc2d4 |\n",
       "| lrc | robust scaling        | 0.8256 | 0.8526 | 0.8351 | 0.8133 | 0.6484 | 22.060 | 0.3253 | 0.5500 | 0.6040 | 0.06880 | 3ed1fbc |\n",
       "| lrc | isomap                | 0.7442 | 0.7849 | 0.7526 | 0.7333 | 0.4859 |  8.365 | 0.1731 | 0.3667 | 0.5397 | 0.07043 | 09c73d2 |\n",
       "| lrc | feature agglomeration | 0.8256 | 0.8526 | 0.8351 | 0.8133 | 0.6484 | 22.060 | 0.3253 | 0.5500 | 0.6040 | 0.06880 | f6ca049 |\n",
       "| lrc | factor analysis       | 0.8256 | 0.8602 | 0.8247 | 0.8267 | 0.6514 | 22.440 | 0.3274 | 0.4667 | 0.6050 | 0.10020 | 20a1399 |\n",
       "| lrc | standard scaling      | 0.8140 | 0.8495 | 0.8144 | 0.8133 | 0.6278 | 19.120 | 0.3016 | 0.5500 | 0.6040 | 0.06929 | f3b8dbb |\n",
       "| lrc | pca                   | 0.8314 | 0.8469 | 0.8557 | 0.8000 | 0.6557 | 23.710 | 0.3369 | 0.4500 | 0.5569 | 0.05593 | a9faa26 |\n",
       "| lrc | lle                   | 0.8547 | 0.8750 | 0.8660 | 0.8400 | 0.7060 | 33.920 | 0.3948 | 0.7333 | 0.5410 | 0.15540 | 0330f84 |\n",
       "| lrc | lle hessian           | 0.8256 | 0.8602 | 0.8247 | 0.8267 | 0.6514 | 22.440 | 0.3274 | 0.5500 | 0.5934 | 0.09136 | f89dea8 |\n",
       "| lrc | lle modified          | 0.8140 | 0.8495 | 0.8144 | 0.8133 | 0.6278 | 19.120 | 0.3016 | 0.5500 | 0.6168 | 0.07125 | 9a8b7e3 |\n",
       "| lrc | nca                   | 0.8314 | 0.8617 | 0.8351 | 0.8267 | 0.6617 | 24.140 | 0.3396 | 0.5500 | 0.5639 | 0.08217 | a9e7758 |\n",
       "| lrc | none                  | 0.8140 | 0.8495 | 0.8144 | 0.8133 | 0.6278 | 19.120 | 0.3016 | 0.5500 | 0.6040 | 0.06929 | eebed59 |\n",
       "\n"
      ],
      "text/plain": [
       "   model preprocessing         accuracy precision sensitivity specificity\n",
       "1  qda   robust scaling        0.8140   0.8095    0.8763      0.7333     \n",
       "2  lda   robust scaling        0.8140   0.8155    0.8660      0.7467     \n",
       "3  dtc   robust scaling        0.7791   0.7565    0.8969      0.6267     \n",
       "4  sgb   robust scaling        0.8081   0.7963    0.8866      0.7067     \n",
       "5  rfc   robust scaling        0.8314   0.8269    0.8866      0.7600     \n",
       "6  rfc   isomap                0.8081   0.8200    0.8454      0.7600     \n",
       "7  rfc   pca                   0.8430   0.8365    0.8969      0.7733     \n",
       "8  rfc   lle                   0.7965   0.8444    0.7835      0.8133     \n",
       "9  rfc   lle hessian           0.8198   0.8235    0.8660      0.7600     \n",
       "10 rfc   lle modified          0.7849   0.8061    0.8144      0.7467     \n",
       "11 rfc   factor analysis       0.8023   0.8387    0.8041      0.8000     \n",
       "12 rfc   feature agglomeration 0.8081   0.8200    0.8454      0.7600     \n",
       "13 rfc   nca                   0.8081   0.8404    0.8144      0.8000     \n",
       "14 rfc   standard scaling      0.8023   0.8119    0.8454      0.7467     \n",
       "15 rfc   none                  0.8023   0.8119    0.8454      0.7467     \n",
       "16 rnc   robust scaling        0.8198   0.8438    0.8351      0.8000     \n",
       "17 knn   robust scaling        0.8372   0.8791    0.8247      0.8533     \n",
       "18 knn   standard scaling      0.8198   0.8367    0.8454      0.7867     \n",
       "19 knn   none                  0.7384   0.7321    0.8454      0.6000     \n",
       "20 knn   pca                   0.8372   0.8286    0.8969      0.7600     \n",
       "21 knn   isomap                0.8140   0.8155    0.8660      0.7467     \n",
       "22 knn   lle hessian           0.8023   0.8387    0.8041      0.8000     \n",
       "23 knn   lle                   0.8198   0.8235    0.8660      0.7600     \n",
       "24 knn   lle modified          0.8081   0.8077    0.8660      0.7333     \n",
       "25 knn   factor analysis       0.8721   0.8788    0.8969      0.8400     \n",
       "26 knn   feature agglomeration 0.8372   0.8791    0.8247      0.8533     \n",
       "27 knn   nca                   0.8256   0.8252    0.8763      0.7600     \n",
       "28 lrc   robust scaling        0.8256   0.8526    0.8351      0.8133     \n",
       "29 lrc   isomap                0.7442   0.7849    0.7526      0.7333     \n",
       "30 lrc   feature agglomeration 0.8256   0.8526    0.8351      0.8133     \n",
       "31 lrc   factor analysis       0.8256   0.8602    0.8247      0.8267     \n",
       "32 lrc   standard scaling      0.8140   0.8495    0.8144      0.8133     \n",
       "33 lrc   pca                   0.8314   0.8469    0.8557      0.8000     \n",
       "34 lrc   lle                   0.8547   0.8750    0.8660      0.8400     \n",
       "35 lrc   lle hessian           0.8256   0.8602    0.8247      0.8267     \n",
       "36 lrc   lle modified          0.8140   0.8495    0.8144      0.8133     \n",
       "37 lrc   nca                   0.8314   0.8617    0.8351      0.8267     \n",
       "38 lrc   none                  0.8140   0.8495    0.8144      0.8133     \n",
       "   informedness dor    ami    outlier informedness cv informedness\n",
       "1  0.6096       19.480 0.2993 0.4833               0.6036         \n",
       "2  0.6126       19.040 0.2981 0.5500               0.5782         \n",
       "3  0.5236       14.600 0.2389 0.6500               0.5143         \n",
       "4  0.5933       18.830 0.2895 0.5667               0.5879         \n",
       "5  0.6466       24.760 0.3384 0.5500               0.5627         \n",
       "6  0.6054       17.310 0.2851 0.4667               0.6357         \n",
       "7  0.6702       29.680 0.3668 0.6500               0.5782         \n",
       "8  0.5968       15.770 0.2693 0.4667               0.5334         \n",
       "9  0.6260       20.460 0.3105 0.4833               0.5205         \n",
       "10 0.5611       12.940 0.2394 0.4667               0.5314         \n",
       "11 0.6041       16.420 0.2772 0.4500               0.5743         \n",
       "12 0.6054       17.310 0.2851 0.6500               0.5835         \n",
       "13 0.6144       17.560 0.2882 0.4500               0.5196         \n",
       "14 0.5920       16.110 0.2731 0.6500               0.5421         \n",
       "15 0.5920       16.110 0.2731 0.6500               0.5421         \n",
       "16 0.6351       20.250 0.3116 0.4500               0.6162         \n",
       "17 0.6781       27.380 0.3575 0.5500               0.6219         \n",
       "18 0.6320       20.160 0.3105 0.6643               0.1176         \n",
       "19 0.4454        8.200 0.1621 0.3167               0.4592         \n",
       "20 0.6569       27.550 0.3535 0.7500               0.5506         \n",
       "21 0.6126       19.040 0.2981 0.5500               0.6076         \n",
       "22 0.6041       16.420 0.2772 0.2667               0.5712         \n",
       "23 0.6260       20.460 0.3105 0.5667               0.5869         \n",
       "24 0.5993       17.770 0.2860 0.4667               0.5676         \n",
       "25 0.7369       45.670 0.4408 0.6333               0.6164         \n",
       "26 0.6781       27.380 0.3575 0.5500               0.6219         \n",
       "27 0.6363       22.430 0.3241 0.4667               0.5450         \n",
       "28 0.6484       22.060 0.3253 0.5500               0.6040         \n",
       "29 0.4859        8.365 0.1731 0.3667               0.5397         \n",
       "30 0.6484       22.060 0.3253 0.5500               0.6040         \n",
       "31 0.6514       22.440 0.3274 0.4667               0.6050         \n",
       "32 0.6278       19.120 0.3016 0.5500               0.6040         \n",
       "33 0.6557       23.710 0.3369 0.4500               0.5569         \n",
       "34 0.7060       33.920 0.3948 0.7333               0.5410         \n",
       "35 0.6514       22.440 0.3274 0.5500               0.5934         \n",
       "36 0.6278       19.120 0.3016 0.5500               0.6168         \n",
       "37 0.6617       24.140 0.3396 0.5500               0.5639         \n",
       "38 0.6278       19.120 0.3016 0.5500               0.6040         \n",
       "   mad informedness commit hash\n",
       "1  0.08135          5236d5b    \n",
       "2  0.07821          9b44485    \n",
       "3  0.07692          ad170e6    \n",
       "4  0.07756          87c9f52    \n",
       "5  0.08640          604f618    \n",
       "6  0.11830          614ff30    \n",
       "7  0.09998          e16ba46    \n",
       "8  0.14640          4bdf43f    \n",
       "9  0.09570          3be6109    \n",
       "10 0.10560          72f0897    \n",
       "11 0.10300          08a08cd    \n",
       "12 0.10070          0be2375    \n",
       "13 0.11650          59c3c02    \n",
       "14 0.09368          16e71aa    \n",
       "15 0.09368          cde032e    \n",
       "16 0.08429          c47f862    \n",
       "17 0.10520          3ee0a51    \n",
       "18 0.46670          2544121    \n",
       "19 0.07587          26c115c    \n",
       "20 0.12090          7ace118    \n",
       "21 0.08374          38c3c33    \n",
       "22 0.13890          b85af4b    \n",
       "23 0.10690          0191ede    \n",
       "24 0.12940          5af463b    \n",
       "25 0.10710          05e50d5    \n",
       "26 0.10520          10fa6ee    \n",
       "27 0.09647          cfdc2d4    \n",
       "28 0.06880          3ed1fbc    \n",
       "29 0.07043          09c73d2    \n",
       "30 0.06880          f6ca049    \n",
       "31 0.10020          20a1399    \n",
       "32 0.06929          f3b8dbb    \n",
       "33 0.05593          a9faa26    \n",
       "34 0.15540          0330f84    \n",
       "35 0.09136          f89dea8    \n",
       "36 0.07125          9a8b7e3    \n",
       "37 0.08217          a9e7758    \n",
       "38 0.06929          eebed59    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Selection\n",
    "# ===============\n",
    "# This notebook compares the scores of different model algorithms, \n",
    "# preprocessing methods, and classification methods.\n",
    "#\n",
    "# Copyright 2020, 2021 Jerrad M. Genson\n",
    "#\n",
    "# This Source Code Form is subject to the terms of the Mozilla Public\n",
    "# License, v. 2.0. If a copy of the MPL was not distributed with this\n",
    "# file, You can obtain one at https://mozilla.org/MPL/2.0/.\n",
    "\n",
    "library(tidyverse)\n",
    "\n",
    "GIT_ROOT <- system2('git', args=c('rev-parse', '--show-toplevel'), stdout=TRUE)\n",
    "DATA <- file.path(GIT_ROOT, 'data')\n",
    "MODEL_DATA <- file.path(DATA, 'model_selection.csv')\n",
    "\n",
    "scores <- read_csv(MODEL_DATA)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>knn</td><td>factor analysis</td><td>0.8721</td><td>0.8788</td><td>0.8969</td><td>0.84</td><td>0.7369</td><td>45.67</td><td>0.4408</td><td>0.6333</td><td>0.6164</td><td>0.1071</td><td>05e50d5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t knn & factor analysis & 0.8721 & 0.8788 & 0.8969 & 0.84 & 0.7369 & 45.67 & 0.4408 & 0.6333 & 0.6164 & 0.1071 & 05e50d5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| knn | factor analysis | 0.8721 | 0.8788 | 0.8969 | 0.84 | 0.7369 | 45.67 | 0.4408 | 0.6333 | 0.6164 | 0.1071 | 05e50d5 |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing   accuracy precision sensitivity specificity informedness\n",
       "1 knn   factor analysis 0.8721   0.8788    0.8969      0.84        0.7369      \n",
       "  dor   ami    outlier informedness cv informedness mad informedness\n",
       "1 45.67 0.4408 0.6333               0.6164          0.1071          \n",
       "  commit hash\n",
       "1 05e50d5    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_informedness <- scores[scores$informedness == max(scores$informedness), ]\n",
    "best_informedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>knn</td><td>factor analysis</td><td>0.8721</td><td>0.8788</td><td>0.8969</td><td>0.84</td><td>0.7369</td><td>45.67</td><td>0.4408</td><td>0.6333</td><td>0.6164</td><td>0.1071</td><td>05e50d5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t knn & factor analysis & 0.8721 & 0.8788 & 0.8969 & 0.84 & 0.7369 & 45.67 & 0.4408 & 0.6333 & 0.6164 & 0.1071 & 05e50d5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| knn | factor analysis | 0.8721 | 0.8788 | 0.8969 | 0.84 | 0.7369 | 45.67 | 0.4408 | 0.6333 | 0.6164 | 0.1071 | 05e50d5 |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing   accuracy precision sensitivity specificity informedness\n",
       "1 knn   factor analysis 0.8721   0.8788    0.8969      0.84        0.7369      \n",
       "  dor   ami    outlier informedness cv informedness mad informedness\n",
       "1 45.67 0.4408 0.6333               0.6164          0.1071          \n",
       "  commit hash\n",
       "1 05e50d5    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_dor <- scores[scores$dor == max(scores$dor), ]\n",
    "best_dor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 4 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>dtc</td><td>robust scaling </td><td>0.7791</td><td>0.7565</td><td>0.8969</td><td>0.6267</td><td>0.5236</td><td>14.60</td><td>0.2389</td><td>0.6500</td><td>0.5143</td><td>0.07692</td><td>ad170e6</td></tr>\n",
       "\t<tr><td>rfc</td><td>pca            </td><td>0.8430</td><td>0.8365</td><td>0.8969</td><td>0.7733</td><td>0.6702</td><td>29.68</td><td>0.3668</td><td>0.6500</td><td>0.5782</td><td>0.09998</td><td>e16ba46</td></tr>\n",
       "\t<tr><td>knn</td><td>pca            </td><td>0.8372</td><td>0.8286</td><td>0.8969</td><td>0.7600</td><td>0.6569</td><td>27.55</td><td>0.3535</td><td>0.7500</td><td>0.5506</td><td>0.12090</td><td>7ace118</td></tr>\n",
       "\t<tr><td>knn</td><td>factor analysis</td><td>0.8721</td><td>0.8788</td><td>0.8969</td><td>0.8400</td><td>0.7369</td><td>45.67</td><td>0.4408</td><td>0.6333</td><td>0.6164</td><td>0.10710</td><td>05e50d5</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 4 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t dtc & robust scaling  & 0.7791 & 0.7565 & 0.8969 & 0.6267 & 0.5236 & 14.60 & 0.2389 & 0.6500 & 0.5143 & 0.07692 & ad170e6\\\\\n",
       "\t rfc & pca             & 0.8430 & 0.8365 & 0.8969 & 0.7733 & 0.6702 & 29.68 & 0.3668 & 0.6500 & 0.5782 & 0.09998 & e16ba46\\\\\n",
       "\t knn & pca             & 0.8372 & 0.8286 & 0.8969 & 0.7600 & 0.6569 & 27.55 & 0.3535 & 0.7500 & 0.5506 & 0.12090 & 7ace118\\\\\n",
       "\t knn & factor analysis & 0.8721 & 0.8788 & 0.8969 & 0.8400 & 0.7369 & 45.67 & 0.4408 & 0.6333 & 0.6164 & 0.10710 & 05e50d5\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 4 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| dtc | robust scaling  | 0.7791 | 0.7565 | 0.8969 | 0.6267 | 0.5236 | 14.60 | 0.2389 | 0.6500 | 0.5143 | 0.07692 | ad170e6 |\n",
       "| rfc | pca             | 0.8430 | 0.8365 | 0.8969 | 0.7733 | 0.6702 | 29.68 | 0.3668 | 0.6500 | 0.5782 | 0.09998 | e16ba46 |\n",
       "| knn | pca             | 0.8372 | 0.8286 | 0.8969 | 0.7600 | 0.6569 | 27.55 | 0.3535 | 0.7500 | 0.5506 | 0.12090 | 7ace118 |\n",
       "| knn | factor analysis | 0.8721 | 0.8788 | 0.8969 | 0.8400 | 0.7369 | 45.67 | 0.4408 | 0.6333 | 0.6164 | 0.10710 | 05e50d5 |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing   accuracy precision sensitivity specificity informedness\n",
       "1 dtc   robust scaling  0.7791   0.7565    0.8969      0.6267      0.5236      \n",
       "2 rfc   pca             0.8430   0.8365    0.8969      0.7733      0.6702      \n",
       "3 knn   pca             0.8372   0.8286    0.8969      0.7600      0.6569      \n",
       "4 knn   factor analysis 0.8721   0.8788    0.8969      0.8400      0.7369      \n",
       "  dor   ami    outlier informedness cv informedness mad informedness\n",
       "1 14.60 0.2389 0.6500               0.5143          0.07692         \n",
       "2 29.68 0.3668 0.6500               0.5782          0.09998         \n",
       "3 27.55 0.3535 0.7500               0.5506          0.12090         \n",
       "4 45.67 0.4408 0.6333               0.6164          0.10710         \n",
       "  commit hash\n",
       "1 ad170e6    \n",
       "2 e16ba46    \n",
       "3 7ace118    \n",
       "4 05e50d5    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_sensitivity <- scores[scores$sensitivity == max(scores$sensitivity), ]\n",
    "best_sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>rfc</td><td>isomap</td><td>0.8081</td><td>0.82</td><td>0.8454</td><td>0.76</td><td>0.6054</td><td>17.31</td><td>0.2851</td><td>0.4667</td><td>0.6357</td><td>0.1183</td><td>614ff30</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t rfc & isomap & 0.8081 & 0.82 & 0.8454 & 0.76 & 0.6054 & 17.31 & 0.2851 & 0.4667 & 0.6357 & 0.1183 & 614ff30\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| rfc | isomap | 0.8081 | 0.82 | 0.8454 | 0.76 | 0.6054 | 17.31 | 0.2851 | 0.4667 | 0.6357 | 0.1183 | 614ff30 |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing accuracy precision sensitivity specificity informedness\n",
       "1 rfc   isomap        0.8081   0.82      0.8454      0.76        0.6054      \n",
       "  dor   ami    outlier informedness cv informedness mad informedness\n",
       "1 17.31 0.2851 0.4667               0.6357          0.1183          \n",
       "  commit hash\n",
       "1 614ff30    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_cv_informedness <- scores[scores$`cv informedness` == max(scores$`cv informedness`), ]\n",
    "best_cv_informedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 1 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>lrc</td><td>lle</td><td>0.8547</td><td>0.875</td><td>0.866</td><td>0.84</td><td>0.706</td><td>33.92</td><td>0.3948</td><td>0.7333</td><td>0.541</td><td>0.1554</td><td>0330f84</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 1 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t lrc & lle & 0.8547 & 0.875 & 0.866 & 0.84 & 0.706 & 33.92 & 0.3948 & 0.7333 & 0.541 & 0.1554 & 0330f84\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 1 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| lrc | lle | 0.8547 | 0.875 | 0.866 | 0.84 | 0.706 | 33.92 | 0.3948 | 0.7333 | 0.541 | 0.1554 | 0330f84 |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing accuracy precision sensitivity specificity informedness\n",
       "1 lrc   lle           0.8547   0.875     0.866       0.84        0.706       \n",
       "  dor   ami    outlier informedness cv informedness mad informedness\n",
       "1 33.92 0.3948 0.7333               0.541           0.1554          \n",
       "  commit hash\n",
       "1 0330f84    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "second_best_informedness <- scores[scores$informedness == unique(sort(scores$informedness, TRUE))[2], ]\n",
    "second_best_informedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 2 × 13</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>preprocessing</th><th scope=col>accuracy</th><th scope=col>precision</th><th scope=col>sensitivity</th><th scope=col>specificity</th><th scope=col>informedness</th><th scope=col>dor</th><th scope=col>ami</th><th scope=col>outlier informedness</th><th scope=col>cv informedness</th><th scope=col>mad informedness</th><th scope=col>commit hash</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>knn</td><td>robust scaling       </td><td>0.8372</td><td>0.8791</td><td>0.8247</td><td>0.8533</td><td>0.6781</td><td>27.38</td><td>0.3575</td><td>0.55</td><td>0.6219</td><td>0.1052</td><td>3ee0a51</td></tr>\n",
       "\t<tr><td>knn</td><td>feature agglomeration</td><td>0.8372</td><td>0.8791</td><td>0.8247</td><td>0.8533</td><td>0.6781</td><td>27.38</td><td>0.3575</td><td>0.55</td><td>0.6219</td><td>0.1052</td><td>10fa6ee</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 13\n",
       "\\begin{tabular}{lllllllllllll}\n",
       " model & preprocessing & accuracy & precision & sensitivity & specificity & informedness & dor & ami & outlier informedness & cv informedness & mad informedness & commit hash\\\\\n",
       " <chr> & <chr> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <chr>\\\\\n",
       "\\hline\n",
       "\t knn & robust scaling        & 0.8372 & 0.8791 & 0.8247 & 0.8533 & 0.6781 & 27.38 & 0.3575 & 0.55 & 0.6219 & 0.1052 & 3ee0a51\\\\\n",
       "\t knn & feature agglomeration & 0.8372 & 0.8791 & 0.8247 & 0.8533 & 0.6781 & 27.38 & 0.3575 & 0.55 & 0.6219 & 0.1052 & 10fa6ee\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 13\n",
       "\n",
       "| model &lt;chr&gt; | preprocessing &lt;chr&gt; | accuracy &lt;dbl&gt; | precision &lt;dbl&gt; | sensitivity &lt;dbl&gt; | specificity &lt;dbl&gt; | informedness &lt;dbl&gt; | dor &lt;dbl&gt; | ami &lt;dbl&gt; | outlier informedness &lt;dbl&gt; | cv informedness &lt;dbl&gt; | mad informedness &lt;dbl&gt; | commit hash &lt;chr&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| knn | robust scaling        | 0.8372 | 0.8791 | 0.8247 | 0.8533 | 0.6781 | 27.38 | 0.3575 | 0.55 | 0.6219 | 0.1052 | 3ee0a51 |\n",
       "| knn | feature agglomeration | 0.8372 | 0.8791 | 0.8247 | 0.8533 | 0.6781 | 27.38 | 0.3575 | 0.55 | 0.6219 | 0.1052 | 10fa6ee |\n",
       "\n"
      ],
      "text/plain": [
       "  model preprocessing         accuracy precision sensitivity specificity\n",
       "1 knn   robust scaling        0.8372   0.8791    0.8247      0.8533     \n",
       "2 knn   feature agglomeration 0.8372   0.8791    0.8247      0.8533     \n",
       "  informedness dor   ami    outlier informedness cv informedness\n",
       "1 0.6781       27.38 0.3575 0.55                 0.6219         \n",
       "2 0.6781       27.38 0.3575 0.55                 0.6219         \n",
       "  mad informedness commit hash\n",
       "1 0.1052           3ee0a51    \n",
       "2 0.1052           10fa6ee    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "third_best_informedness <- scores[scores$informedness == unique(sort(scores$informedness, TRUE))[3], ]\n",
    "third_best_informedness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
